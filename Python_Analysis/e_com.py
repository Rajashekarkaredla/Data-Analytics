# -*- coding: utf-8 -*-
"""E-com.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-6k81NVHoV4Vx_4wHJcUeRv31GohsYbJ
"""

from google.colab import files
uploaded = files.upload()
import pandas as pd
ec_df=pd.read_csv('E-com.csv')
ec_df

#checking for null values
ec_df.isnull().sum()
#check for duplicates
#ec_df[ec_df.duplicated()]

#checking fo any duplicate order id
ec_df['Order ID'].duplicated().sum()

#Number of unique customers
ec_df['Order ID'].nunique()

#Number of unique customers
ec_df['Customer ID'].nunique()

#Average orders per customer
round(ec_df['Order ID'].count()/(ec_df['Customer ID'].nunique()),0)

#orders of each customer
ec_df['Customer ID'].value_counts()

#Platform-wise percentage of order count
(ec_df['Platform'].value_counts()/len(ec_df)*100).reset_index()

#Platform-wise of order count
ec_df['Platform'].value_counts()

#top platform used
ec_df['Platform'].value_counts().idxmax()

import pandas as pd

def convert_to_datetime(time_str):
    try:
        # Attempt to split with 2 colons (HH:MM:SS)
        hours, minutes, seconds = map(float, time_str.split(":"))
        return pd.Timedelta(hours=hours, minutes=minutes, seconds=seconds)
    except ValueError:
        try:
            # If that fails, try splitting with 1 colon (HH:MM)
            hours, minutes = map(float, time_str.split(":"))
            return pd.Timedelta(hours=hours, minutes=minutes)
        except ValueError:
            # If both fail, handle the error (e.g., return NaT or print a message)

            return pd.NaT  # Return Not a Time

ec_df["timedelta"] = ec_df["Order Date & Time"].apply(convert_to_datetime)
base_date = pd.Timestamp("2025-04-17")
ec_df["date_time"] = base_date + ec_df["timedelta"]
ec_df["date_time"]

#extracting hours column
ec_df['order_hour']=ec_df['date_time'].dt.hour
ec_df['order_hour']

#changing 0hr to 24
ec_df.loc[ec_df['order_hour'] == 0, 'order_hour'] = 24
ec_df['order_hour']

#finding peek order hour
ec_df['order_hour'].value_counts().dxmax#sort_values(ascending=False).reset_index().head(1)

#average delivary time
ec_df['Delivery Time (Minutes)'].mean()

#product category take maximum time to delivary
ec_df.sort_values(by='Delivery Time (Minutes)',ascending=False)[['Delivery Time (Minutes)','Product Category']].head(1)

#product category take minimum time to delivary
ec_df.sort_values(by='Delivery Time (Minutes)',ascending=True)[['Delivery Time (Minutes)','Product Category']].head(1)

#platform with total order values
ec_df.groupby('Platform')['Order Value (INR)'].sum().reset_index()

#average order values
ec_df['Order Value (INR)'].mean()

#high value orders(greater than 1000 INR)
ec_df[ec_df['Order Value (INR)']>1000][['Platform','Product Category']]

#products that ordered
ec_df['Product Category'].value_counts().sort_values(ascending=False).reset_index()

#total values of products
ec_df.groupby('Product Category')['Order Value (INR)'].sum().sort_values(ascending=False).reset_index()

#highest order value
ec_df.sort_values(by='Order Value (INR)',ascending=False)[['Order Value (INR)','Customer ID','Product Category','Platform']].head(1)

#lowest order value
ec_df.sort_values(by='Order Value (INR)',ascending=True)[['Order Value (INR)','Customer ID','Product Category','Platform']].head(1)

#approx number of good feedbacks
ec_df['Customer Feedback'].str.contains("good|excellent|fast|great|Quick|satisfied|Easy|loved", case=False, na=False).value_counts().reset_index()

(ec_df['Customer Feedback'].str.contains("good|excellent|fast|great|Quick|satisfied|Easy|loved", case=False, na=False).value_counts()/len(ec_df)*100).reset_index()

#best orders
ec_df[(ec_df['Service Rating']==5) & (ec_df['Order Value (INR)']<100) & (ec_df['Delivery Time (Minutes)']<6)]

#best products
ec_df[(ec_df['Service Rating']==5) & (ec_df['Order Value (INR)']<100) & (ec_df['Delivery Time (Minutes)']<6)]['Product Category'].unique()

#total Refund Requested
ec_df['Refund Requested'].value_counts().reset_index()

#total percentage of Refund Requests
(ec_df['Refund Requested'].value_counts()/len(ec_df)*100).reset_index()

ec_df[ec_df['Delivery Delay']=='Yes']['Refund Requested'].value_counts().reset_index()

ec_df[ec_df['Service Rating']<2]['Refund Requested'].value_counts().reset_index()

#verification
import matplotlib.pyplot as plt
plt.boxplot(ec_df['Order Value (INR)'])
plt.show()

#correlation
corr=ec_df[['Delivery Time (Minutes)','order_hour','Service Rating','Order Value (INR)']].corr()

import seaborn as sns
sns.heatmap(ec_df[['Delivery Time (Minutes)','order_hour','Service Rating','Order Value (INR)']],annot=True,cmap='coolwarm')

ec_df.columns

import plotly.express as ex
sns.countplot(data=ec_df,x='Platform')

plt.hist(ec_df['Delivery Time (Minutes)'], bins=10, color='blue', edgecolor='black')
plt.xlabel('Delivery Time (Minutes)')
plt.ylabel('Frequency')
plt.show()

sns.barplot(data=ec_df,x='Delivery Time (Minutes)',y='Product Category',hue='Platform')

import matplotlib.pyplot as plt
import seaborn as sns
sns.barplot(data=ec_df,x='Service Rating',y='order_hour',hue='Refund Requested')
plt.show()

ex.scatter_3d(data_frame=ec_df,x='Order Value (INR)',y='Delivery Time (Minutes)',z='Platform',color='Refund Requested',size='Delivery Time (Minutes)')

ec_df.columns

# Save the DataFrame to a CSV file
ec_df.to_csv('modified_dataset.csv', index=False)
# Download the file to your local machine
from google.colab import files
files.download('modified_dataset.csv')