# -*- coding: utf-8 -*-
"""Chat with sheets using AI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dNDA3cSjCeCCYBkOtmRoB0nOapc-MjnW
"""

!pip install -q google-generativeai faiss-cpu sentence-transformers gspread oauth2client

import google.generativeai as genai

genai.configure(api_key="API_KEY")  # Replace with your Gemini API Key

gemini_model = genai.GenerativeModel("gemini-2.5-flash")

from google.colab import files
uploaded = files.upload()  # Upload credentials.json

import gspread
from oauth2client.service_account import ServiceAccountCredentials

# Set up credentials
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
creds = ServiceAccountCredentials.from_json_keyfile_name("credentials.json", scope)
client = gspread.authorize(creds)

# List of sheet URLs
sheet_urls = [
    "Sheet1",
    "Sheet2"
]

# Combine all sheet data (including headers)
sheet_text = ""

for url in sheet_urls:
    sheet = client.open_by_url(url).sheet1
    data = sheet.get_all_values()  # Includes header
    sheet_text += "\n".join([", ".join(row) for row in data]) + "\n"

#print(sheet_text[:1000])  # preview first 1000 characters (optional)

def chunk_text(text, chunk_size=300):
    sentences = text.split(". ")
    chunks = []
    current_chunk = ""
    for sentence in sentences:
        if len(current_chunk) + len(sentence) <= chunk_size:
            current_chunk += sentence + ". "
        else:
            chunks.append(current_chunk.strip())
            current_chunk = sentence + ". "
    if current_chunk:
        chunks.append(current_chunk.strip())
    return chunks

chunks = chunk_text(sheet_text)

from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

embedder = SentenceTransformer('all-MiniLM-L6-v2')
chunk_embeddings = embedder.encode(chunks)

index = faiss.IndexFlatL2(chunk_embeddings[0].shape[0])
index.add(np.array(chunk_embeddings))

def ask_sheet_question(query):
    query_vec = embedder.encode([query])
    D, I = index.search(np.array(query_vec), k=3)
    retrieved = "\n".join([chunks[i] for i in I[0]])

    prompt = f"""Use the below context from a Google Sheet to answer the question:

Context:
{retrieved}

Question: {query}
Answer:"""

    response = gemini_model.generate_content(prompt)
    return response.text

while True:
    q = input("Ask a question about your sheet (type 'exit' to quit): ")
    if q.lower() == 'exit':
        break
    print("Answer:", ask_sheet_question(q))